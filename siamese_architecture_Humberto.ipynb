{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_architecture_Humberto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lian999111/CVDL-Parametrizable-Classification/blob/master/siamese_architecture_Humberto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-SGIUayCFqk",
        "colab_type": "text"
      },
      "source": [
        "Import tensorflow 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_EFJei-h4NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XgpwlMZB6yc",
        "colab_type": "text"
      },
      "source": [
        "Import Dataset (MNIST or CIFAR10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grCJhtEQB4U3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset( dataset = 'mnist', \n",
        "    used_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \n",
        "    training_size = 60000, \n",
        "    test_size = 10000 ):\n",
        "    \"\"\" \n",
        "    Reads and converts data from the MNIST dataset. \n",
        "\n",
        "    :param  dataset         'mnist' or 'cifar10'\n",
        "    :param  used_labels     list of digit classes to include into the returned subset\n",
        "    :param  training_size   number of images from training size\n",
        "    :param  test_size       number of images from test_size\n",
        "\n",
        "    :return x_train, y_train, x_test, y_test, class_names    \n",
        "      x_train, x_test: training and test images (uint8 [0- 255], shape: training_size x 28 x 28, test_size x 28 x 28),\n",
        "      y_train, y_test: corresponding labels (int32 [0 - len(used_labels)), shape: training_size / test_size)\n",
        "      class_names: array with names of classes (size: len(used_labels))\n",
        "    \"\"\"\n",
        "\n",
        "    num_classes = len(used_labels)\n",
        "    max_num_classes = 10\n",
        "\n",
        "\n",
        "    np.random.seed(4711)\n",
        "\n",
        "    if dataset == 'mnist':\n",
        "        (x_train, y_train),(x_test, y_test) = mnist.load_data() # x_train.shape = 60,000 x 28 x 28\n",
        "\n",
        "        class_names = map(str, used_labels)\n",
        "    elif dataset == 'cifar10':\n",
        "\n",
        "        if not os.path.isfile(cifar_path + r'\\data_batch_1'):\n",
        "            raise FileNotFoundError('The path %s does not seem to contain the CIFAR-10 dataset. ' % (cifar_path) )\n",
        "\n",
        "        np_x_train_file = cifar_path + r'\\numpy_dump_x_train.npy'\n",
        "        np_y_train_file = cifar_path + r'\\numpy_dump_y_train.npy'\n",
        "        np_x_test_file = cifar_path + r'\\numpy_dump_x_test.npy'\n",
        "        np_y_test_file = cifar_path + r'\\numpy_dump_y_test.npy'\n",
        "\n",
        "        if not os.path.isfile(np_x_train_file): # first time loading\n",
        "\n",
        "            file_idxs = [1, 2, 3, 4, 5] # which cifar batches 1..5 should be loaded\n",
        "\n",
        "            # fills the labels and data variables\n",
        "            # labels contains the NR class labels 0..9 of each CIFAR image\n",
        "            # data is an array NR x 3072 where each line contains the pixel information of a CIFAR image, the memory layout is RGB, column, row \n",
        "            for file_idx in file_idxs:\n",
        "                with open( (cifar_path + r'\\data_batch_%d') % file_idx, 'rb') as cifar_file:\n",
        "                    dict = pickle.load(cifar_file, encoding='bytes')\n",
        "                    if not 'y_train' in locals():\n",
        "                        y_train = np.array( dict[b'labels'], np.int32 )\n",
        "                        x_train = dict[b'data']\n",
        "                    else:\n",
        "                        y_train = np.concatenate( (y_train, np.array( dict[b'labels'], np.int32 )) )\n",
        "                        x_train = np.concatenate( (x_train, dict[b'data']) )\n",
        "\n",
        "            x_train = np.transpose( np.reshape( x_train, [x_train.shape[0], 3, 32, 32] ), [0, 2, 3, 1] )\n",
        "\n",
        "            with open( cifar_path + r'\\test_batch', 'rb') as cifar_file:\n",
        "                dict = pickle.load(cifar_file, encoding='bytes')\n",
        "                y_test = np.array( dict[b'labels'], np.int32 )\n",
        "                x_test = dict[b'data']\n",
        "\n",
        "            x_test = np.transpose( np.reshape( x_test, [x_test.shape[0], 3, 32, 32] ), [0, 2, 3, 1] )\n",
        "\n",
        "            np.save(np_x_train_file, x_train)\n",
        "            np.save(np_y_train_file, y_train)\n",
        "            np.save(np_x_test_file, x_test)\n",
        "            np.save(np_y_test_file, y_test)\n",
        "\n",
        "        else:\n",
        "            x_train = np.load(np_x_train_file)\n",
        "            y_train = np.load(np_y_train_file)\n",
        "            x_test = np.load(np_x_test_file)\n",
        "            y_test = np.load(np_y_test_file)\n",
        "\n",
        "        # names of the 10 CIFAR classes                \n",
        "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "        class_names = [class_names[idx] for idx in used_labels]\n",
        "            \n",
        "        \n",
        "    else:\n",
        "        raise ValueError('The variable dataset must either be set to \"mnist\" or \"cifar10\"')\n",
        "\n",
        "    if num_classes != 10:\n",
        "        x_train, y_train = cull_unused_classes(x_train, y_train, used_labels)\n",
        "        x_test, y_test = cull_unused_classes(x_test, y_test, used_labels)\n",
        "\n",
        "    # make the class indices consecutive (only if not all 10 digits are chosen in used_labels)\n",
        "\n",
        "    y_train = make_successive_labels(y_train)\n",
        "    y_test = make_successive_labels(y_test)\n",
        "\n",
        "    original_training_size = x_train.shape[0]\n",
        "    original_test_size = x_test.shape[0]\n",
        "\n",
        "    # take a small random subset of images (size is given in training_size and test_size)\n",
        "    training_idxs = np.arange(original_training_size)\n",
        "    np.random.shuffle(training_idxs)\n",
        "    training_idxs = training_idxs[0:training_size]\n",
        "    x_train = x_train[training_idxs]\n",
        "    y_train = y_train[training_idxs]\n",
        "    y_train = y_train.astype(np.int32)\n",
        "\n",
        "    test_idxs = np.arange(original_test_size)\n",
        "    np.random.shuffle(test_idxs)\n",
        "    test_idxs = test_idxs[0:test_size]\n",
        "    x_test = x_test[test_idxs]\n",
        "    y_test = y_test[test_idxs]\n",
        "    y_test = y_test.astype(np.int32)\n",
        "\n",
        "    x_train = x_train.astype( np.float32 )\n",
        "    x_test = x_test.astype( np.float32 )\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOnTuL8OEAXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "f140666e-82f1-408e-af17-baea7a446026"
      },
      "source": [
        "used_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "training_size = 6000\n",
        "test_size = 1000\n",
        "num_classes = len(used_labels)\n",
        "\n",
        "x_train, y_train, x_test, y_test, class_names = get_dataset('mnist', used_labels, training_size, test_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e2ae3d0d7d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mused_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-6cbfff75c80e>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(dataset, used_labels, training_size, test_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4711\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mnist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    }
  ]
}